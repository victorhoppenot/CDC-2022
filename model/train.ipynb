{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./twitter_sentiment_data.csv')\n",
    "\n",
    "df = df[abs(df['sentiment']) == 1]\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: 0 if x == -1 else 1)\n",
    "df = df.filter(items=['sentiment',\"message\"])\n",
    "df = df.rename(columns={'sentiment':'label'})\n",
    "dataset = Dataset.from_pandas(df)\n",
    "datset = dataset.shuffle(seed=42)\n",
    "train = dataset.select([i for i in range(0, int(len(dataset)*0.8))])\n",
    "test = dataset.select([i for i in range(int(len(dataset)*0.8), len(dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2c0b6a3065445cab0915d54a901a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a430308047485db4ffd219900f1451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "   return tokenizer(examples[\"message\"], truncation=True)\n",
    " \n",
    "tokenized_train = train.map(preprocess_function, batched=True)\n",
    "tokenized_test = test.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    " \n",
    "def compute_metrics(eval_pred):\n",
    "   load_accuracy = load_metric(\"accuracy\")\n",
    "   load_f1 = load_metric(\"f1\")\n",
    "  \n",
    "   logits, labels = eval_pred\n",
    "   predictions = np.argmax(logits, axis=-1)\n",
    "   accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "   f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "   return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b390184f9014cff85a30ad03aa72f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hoppenot\\Desktop\\CDC\\model\\twitter-climate-sentiment-model is already a clone of https://huggingface.co/XerOpred/twitter-climate-sentiment-model. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    " \n",
    "repo_name = \"twitter-climate-sentiment-model\"\n",
    " \n",
    "training_args = TrainingArguments(\n",
    "   output_dir=repo_name,\n",
    "   learning_rate=2e-5,\n",
    "   per_device_train_batch_size=16,\n",
    "   per_device_eval_batch_size=16,\n",
    "   num_train_epochs=2,\n",
    "   weight_decay=0.01,\n",
    "   save_strategy=\"epoch\",\n",
    "   push_to_hub=True,\n",
    ")\n",
    " \n",
    "trainer = Trainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=tokenized_train,\n",
    "   eval_dataset=tokenized_test,\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: message, __index_level_0__. If message, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 21561\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2696\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b939abce190143fba1258c444386152c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3043, 'learning_rate': 1.626112759643917e-05, 'epoch': 0.37}\n",
      "{'loss': 0.2154, 'learning_rate': 1.255192878338279e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to twitter-climate-sentiment-model\\checkpoint-1348\n",
      "Configuration saved in twitter-climate-sentiment-model\\checkpoint-1348\\config.json\n",
      "Model weights saved in twitter-climate-sentiment-model\\checkpoint-1348\\pytorch_model.bin\n",
      "tokenizer config file saved in twitter-climate-sentiment-model\\checkpoint-1348\\tokenizer_config.json\n",
      "Special tokens file saved in twitter-climate-sentiment-model\\checkpoint-1348\\special_tokens_map.json\n",
      "tokenizer config file saved in twitter-climate-sentiment-model\\tokenizer_config.json\n",
      "Special tokens file saved in twitter-climate-sentiment-model\\special_tokens_map.json\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] The directory name is invalid: 'C:\\\\Users\\\\Hoppenot\\\\AppData\\\\Local\\\\Temp\\\\tmptalh9fq9\\\\lfs_progress'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\shutil.py:625\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 625\u001b[0m     os\u001b[39m.\u001b[39;49munlink(fullname)\n\u001b[0;32m    626\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\Hoppenot\\\\AppData\\\\Local\\\\Temp\\\\tmptalh9fq9\\\\lfs_progress'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\tempfile.py:805\u001b[0m, in \u001b[0;36mTemporaryDirectory._rmtree.<locals>.onerror\u001b[1;34m(func, path, exc_info)\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 805\u001b[0m     _os\u001b[39m.\u001b[39;49munlink(path)\n\u001b[0;32m    806\u001b[0m \u001b[39m# PermissionError is raised on FreeBSD for directories\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\Hoppenot\\\\AppData\\\\Local\\\\Temp\\\\tmptalh9fq9\\\\lfs_progress'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Hoppenot\\Desktop\\CDC\\model\\train.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Hoppenot/Desktop/CDC/model/train.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:1521\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1518\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1519\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1520\u001b[0m )\n\u001b[1;32m-> 1521\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1522\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1523\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1524\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1525\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1526\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:1855\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1852\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_training_stop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1854\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_epoch_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m-> 1855\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m DebugOption\u001b[39m.\u001b[39mTPU_METRICS_DEBUG \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdebug:\n\u001b[0;32m   1858\u001b[0m     \u001b[39mif\u001b[39;00m is_torch_tpu_available():\n\u001b[0;32m   1859\u001b[0m         \u001b[39m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:2069\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2066\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_to_hp_search(trial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step, metrics)\n\u001b[0;32m   2068\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_save:\n\u001b[1;32m-> 2069\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_checkpoint(model, trial, metrics\u001b[39m=\u001b[39;49mmetrics)\n\u001b[0;32m   2070\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_save(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:2228\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[1;34m(self, model, trial, metrics)\u001b[0m\n\u001b[0;32m   2225\u001b[0m     torch\u001b[39m.\u001b[39msave(rng_states, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrng_state_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mprocess_index\u001b[39m}\u001b[39;00m\u001b[39m.pth\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m   2227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpush_to_hub:\n\u001b[1;32m-> 2228\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_push_from_checkpoint(output_dir)\n\u001b[0;32m   2230\u001b[0m \u001b[39m# Maybe delete some older checkpoints.\u001b[39;00m\n\u001b[0;32m   2231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mshould_save:\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:3370\u001b[0m, in \u001b[0;36mTrainer._push_from_checkpoint\u001b[1;34m(self, checkpoint_folder)\u001b[0m\n\u001b[0;32m   3368\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3369\u001b[0m         commit_message \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining in progress, epoch \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mepoch)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 3370\u001b[0m     _, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpush_in_progress \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepo\u001b[39m.\u001b[39;49mpush_to_hub(\n\u001b[0;32m   3371\u001b[0m         commit_message\u001b[39m=\u001b[39;49mcommit_message, blocking\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, auto_lfs_prune\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m   3372\u001b[0m     )\n\u001b[0;32m   3373\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   3374\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_strategy \u001b[39m==\u001b[39m HubStrategy\u001b[39m.\u001b[39mCHECKPOINT:\n\u001b[0;32m   3375\u001b[0m         \u001b[39m# Move back the checkpoint to its place\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\site-packages\\huggingface_hub\\repository.py:1438\u001b[0m, in \u001b[0;36mRepository.push_to_hub\u001b[1;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[0;32m   1436\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgit_add(auto_lfs_track\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1437\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgit_commit(commit_message)\n\u001b[1;32m-> 1438\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgit_push(\n\u001b[0;32m   1439\u001b[0m     upstream\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39morigin \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_branch\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1440\u001b[0m     blocking\u001b[39m=\u001b[39;49mblocking,\n\u001b[0;32m   1441\u001b[0m     auto_lfs_prune\u001b[39m=\u001b[39;49mauto_lfs_prune,\n\u001b[0;32m   1442\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\site-packages\\huggingface_hub\\repository.py:1213\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[1;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[0;32m   1210\u001b[0m                 logger\u001b[39m.\u001b[39mwarning(stderr)\n\u001b[0;32m   1212\u001b[0m             \u001b[39mif\u001b[39;00m return_code:\n\u001b[1;32m-> 1213\u001b[0m                 \u001b[39mraise\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError(\n\u001b[0;32m   1214\u001b[0m                     return_code, process\u001b[39m.\u001b[39margs, output\u001b[39m=\u001b[39mstdout, stderr\u001b[39m=\u001b[39mstderr\n\u001b[0;32m   1215\u001b[0m                 )\n\u001b[0;32m   1217\u001b[0m \u001b[39mexcept\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m   1218\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(exc\u001b[39m.\u001b[39mstderr)\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\contextlib.py:126\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 126\u001b[0m         \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[0;32m    127\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\site-packages\\huggingface_hub\\repository.py:410\u001b[0m, in \u001b[0;36m_lfs_log_progress\u001b[1;34m()\u001b[0m\n\u001b[0;32m    407\u001b[0m exit_event\u001b[39m.\u001b[39mset()\n\u001b[0;32m    408\u001b[0m x\u001b[39m.\u001b[39mjoin()\n\u001b[1;32m--> 410\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mGIT_LFS_PROGRESS\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m current_lfs_progress_value\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\tempfile.py:830\u001b[0m, in \u001b[0;36mTemporaryDirectory.__exit__\u001b[1;34m(self, exc, value, tb)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc, value, tb):\n\u001b[1;32m--> 830\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcleanup()\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\tempfile.py:834\u001b[0m, in \u001b[0;36mTemporaryDirectory.cleanup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcleanup\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    833\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_finalizer\u001b[39m.\u001b[39mdetach():\n\u001b[1;32m--> 834\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rmtree(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\tempfile.py:816\u001b[0m, in \u001b[0;36mTemporaryDirectory._rmtree\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    814\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[1;32m--> 816\u001b[0m _shutil\u001b[39m.\u001b[39;49mrmtree(name, onerror\u001b[39m=\u001b[39;49monerror)\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\shutil.py:757\u001b[0m, in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    755\u001b[0m     \u001b[39m# can't continue even if onerror hook returns\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m \u001b[39mreturn\u001b[39;00m _rmtree_unsafe(path, onerror)\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\shutil.py:627\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    625\u001b[0m             os\u001b[39m.\u001b[39munlink(fullname)\n\u001b[0;32m    626\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m--> 627\u001b[0m             onerror(os\u001b[39m.\u001b[39;49munlink, fullname, sys\u001b[39m.\u001b[39;49mexc_info())\n\u001b[0;32m    628\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     os\u001b[39m.\u001b[39mrmdir(path)\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\tempfile.py:808\u001b[0m, in \u001b[0;36mTemporaryDirectory._rmtree.<locals>.onerror\u001b[1;34m(func, path, exc_info)\u001b[0m\n\u001b[0;32m    806\u001b[0m     \u001b[39m# PermissionError is raised on FreeBSD for directories\u001b[39;00m\n\u001b[0;32m    807\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mIsADirectoryError\u001b[39;00m, \u001b[39mPermissionError\u001b[39;00m):\n\u001b[1;32m--> 808\u001b[0m         \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_rmtree(path)\n\u001b[0;32m    809\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m    810\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\tempfile.py:816\u001b[0m, in \u001b[0;36mTemporaryDirectory._rmtree\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    814\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[1;32m--> 816\u001b[0m _shutil\u001b[39m.\u001b[39;49mrmtree(name, onerror\u001b[39m=\u001b[39;49monerror)\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\shutil.py:757\u001b[0m, in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    755\u001b[0m     \u001b[39m# can't continue even if onerror hook returns\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m \u001b[39mreturn\u001b[39;00m _rmtree_unsafe(path, onerror)\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\shutil.py:608\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    606\u001b[0m         entries \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(scandir_it)\n\u001b[0;32m    607\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m--> 608\u001b[0m     onerror(os\u001b[39m.\u001b[39;49mscandir, path, sys\u001b[39m.\u001b[39;49mexc_info())\n\u001b[0;32m    609\u001b[0m     entries \u001b[39m=\u001b[39m []\n\u001b[0;32m    610\u001b[0m \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m entries:\n",
      "File \u001b[1;32mc:\\Users\\Hoppenot\\anaconda3\\lib\\shutil.py:605\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_rmtree_unsafe\u001b[39m(path, onerror):\n\u001b[0;32m    604\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 605\u001b[0m         \u001b[39mwith\u001b[39;00m os\u001b[39m.\u001b[39;49mscandir(path) \u001b[39mas\u001b[39;00m scandir_it:\n\u001b[0;32m    606\u001b[0m             entries \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(scandir_it)\n\u001b[0;32m    607\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] The directory name is invalid: 'C:\\\\Users\\\\Hoppenot\\\\AppData\\\\Local\\\\Temp\\\\tmptalh9fq9\\\\lfs_progress'"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: message, __index_level_0__. If message, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5391\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697aad9168cd48398c8afbc23e202dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/337 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hoppenot\\AppData\\Local\\Temp\\ipykernel_884\\1757224399.py:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  load_accuracy = load_metric(\"accuracy\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.27790868282318115, 'eval_accuracy': 0.8940827304767205, 'eval_f1': 0.9371629800814351, 'eval_runtime': 135.2041, 'eval_samples_per_second': 39.873, 'eval_steps_per_second': 2.493, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.27790868282318115,\n",
       " 'eval_accuracy': 0.8940827304767205,\n",
       " 'eval_f1': 0.9371629800814351,\n",
       " 'eval_runtime': 135.2041,\n",
       " 'eval_samples_per_second': 39.873,\n",
       " 'eval_steps_per_second': 2.493,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to twitter-climate-sentiment-model\n",
      "Configuration saved in twitter-climate-sentiment-model\\config.json\n",
      "Model weights saved in twitter-climate-sentiment-model\\pytorch_model.bin\n",
      "tokenizer config file saved in twitter-climate-sentiment-model\\tokenizer_config.json\n",
      "Special tokens file saved in twitter-climate-sentiment-model\\special_tokens_map.json\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Text Classification', 'type': 'text-classification'}}\n",
      "To https://huggingface.co/XerOpred/twitter-climate-sentiment-model\n",
      "   ee7435a..b3e887b  main -> main\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Hoppenot/.cache\\huggingface\\hub\\models--XerOpred--twitter-climate-sentiment-model\\snapshots\\b3e887bfc1252b99457740b1686a2b8ff1017dc7\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"XerOpred/twitter-climate-sentiment-model\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64165871e8bf4e3c9882f556476d63dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Hoppenot/.cache\\huggingface\\hub\\models--XerOpred--twitter-climate-sentiment-model\\snapshots\\b3e887bfc1252b99457740b1686a2b8ff1017dc7\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"XerOpred/twitter-climate-sentiment-model\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Hoppenot/.cache\\huggingface\\hub\\models--XerOpred--twitter-climate-sentiment-model\\snapshots\\b3e887bfc1252b99457740b1686a2b8ff1017dc7\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at XerOpred/twitter-climate-sentiment-model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading file vocab.txt from cache at C:\\Users\\Hoppenot/.cache\\huggingface\\hub\\models--XerOpred--twitter-climate-sentiment-model\\snapshots\\b3e887bfc1252b99457740b1686a2b8ff1017dc7\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\Hoppenot/.cache\\huggingface\\hub\\models--XerOpred--twitter-climate-sentiment-model\\snapshots\\b3e887bfc1252b99457740b1686a2b8ff1017dc7\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\Hoppenot/.cache\\huggingface\\hub\\models--XerOpred--twitter-climate-sentiment-model\\snapshots\\b3e887bfc1252b99457740b1686a2b8ff1017dc7\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Hoppenot/.cache\\huggingface\\hub\\models--XerOpred--twitter-climate-sentiment-model\\snapshots\\b3e887bfc1252b99457740b1686a2b8ff1017dc7\\tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8717246043682099\n",
      "0.9828757047653198\n",
      "0.5142467617988586\n",
      "pos\n",
      "0.980625352859497\n",
      "0.997112512588501\n",
      "0.8374744653701782\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_model = pipeline(model=\"XerOpred/twitter-climate-sentiment-model\")\n",
    "sentiment_model([\"RT @NatGeoChannel: Watch #BeforeTheFlood right here, as @LeoDiCaprio travels the world to tackle climate change https://t.co/LkDehj3tNn httÃƒÂ¢Ã¢â€šÂ¬Ã‚Â¦\"])\n",
    "maximum = 0\n",
    "minimum = 1\n",
    "sums = 0\n",
    "n = 0\n",
    "neg = []\n",
    "for index, row in df.iterrows():\n",
    "    if(row['label'] == 0):\n",
    "        v = sentiment_model(row['message'])[0]['score']\n",
    "        neg.append(v)\n",
    "        if v > maximum:\n",
    "            maximum = v\n",
    "        if v < minimum:\n",
    "            minimum = v\n",
    "        sums += v\n",
    "        n += 1\n",
    "        if n == 100:\n",
    "            break\n",
    "print(sums/n)\n",
    "print(maximum)\n",
    "print(minimum)\n",
    "print(\"pos\")\n",
    "maximum = 0\n",
    "minimum = 1\n",
    "sums = 0\n",
    "n = 0\n",
    "pos = []\n",
    "for index, row in df.iterrows():\n",
    "    if(row['label'] == 1):\n",
    "        v = sentiment_model(row['message'])[0]['score']\n",
    "        pos.append(v)\n",
    "        if v > maximum:\n",
    "            maximum = v\n",
    "        if v < minimum:\n",
    "            minimum = v\n",
    "        sums += v\n",
    "        n += 1\n",
    "        if n == 100:\n",
    "            break\n",
    "print(sums/n)\n",
    "print(maximum)\n",
    "print(minimum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(pos,50, range=(0.9,1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 2., 2., 1.,\n",
       "        3., 0., 1., 2., 1., 1., 7., 0., 0., 0., 1., 1., 1., 5., 1., 2., 2.,\n",
       "        1., 4., 8., 5., 5., 0., 3., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0.9  , 0.902, 0.904, 0.906, 0.908, 0.91 , 0.912, 0.914, 0.916,\n",
       "        0.918, 0.92 , 0.922, 0.924, 0.926, 0.928, 0.93 , 0.932, 0.934,\n",
       "        0.936, 0.938, 0.94 , 0.942, 0.944, 0.946, 0.948, 0.95 , 0.952,\n",
       "        0.954, 0.956, 0.958, 0.96 , 0.962, 0.964, 0.966, 0.968, 0.97 ,\n",
       "        0.972, 0.974, 0.976, 0.978, 0.98 , 0.982, 0.984, 0.986, 0.988,\n",
       "        0.99 , 0.992, 0.994, 0.996, 0.998, 1.   ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAANzklEQVR4nO3db6xkdX3H8ffHXbb8EbKkTAwC14tpQ0NJCuQGRRrSgm2BNZA0PoAEE432xqRSsE3Mmj6gPttE09AmxnSDWC2IMbg0DRuVxkqsSV26yz93XWgFVlygZYmxoG2K2G8fzCwsl7l7z70zZ/a3u+9XMtmZOWfmfn4zs58993fm7ElVIUlq11uOdABJ0uFZ1JLUOItakhpnUUtS4yxqSWrc+j6e9Iwzzqj5+fk+nlqSjkm7du16saoG45b1UtTz8/Ps3Lmzj6eWpGNSkh8tt8ypD0lqnEUtSY2zqCWpcRa1JDXOopakxlnUktS4TkWd5ONJ9iTZneTuJCf2HUySNLRiUSc5C/gTYKGqLgDWAdf3HUySNNR16mM9cFKS9cDJwHP9RZIkHWrFIxOr6tkknwGeAf4HuL+q7l+6XpJFYBFgbm5u2jklTdn85u1j79+3ZdOMk2glXaY+TgeuA84F3g6ckuTGpetV1daqWqiqhcFg7OHqkqQ16DL18V7g6ao6UFW/ALYB7+k3liTpoC5F/Qzw7iQnJwlwJbC331iSpINWLOqq2gHcAzwEfH/0mK0955IkjXT6b06r6lbg1p6zSJLG8MhESWqcRS1JjbOoJalxFrUkNc6ilqTGWdSS1DiLWpIaZ1FLUuMsaklqnEUtSY2zqCWpcRa1JDXOopakxlnUktQ4i1qSGmdRS1Ljupzc9rwkjxxyeSnJLTPIJkmiwxlequoJ4EKAJOuAZ4F7+40lSTpotVMfVwJPVtWP+ggjSXqz1Rb19cDdfQSRJI3X6eS2AEk2ANcCn1xm+SKwCDA3NzeVcNJK5jdvH3v/vi2bZpxE6s9qtqivBh6qqv8ct7CqtlbVQlUtDAaD6aSTJK2qqG/AaQ9JmrlORZ3kZOD3gG39xpEkLdVpjrqq/hv41Z6zSJLG8MhESWqcRS1JjbOoJalxFrUkNc6ilqTGWdSS1DiLWpIaZ1FLUuMsaklqnEUtSY2zqCWpcRa1JDXOopakxlnUktQ4i1qSGmdRS1LjLGpJalzXU3FtTHJPkseT7E1yad/BJElDnU7FBfwV8I2qen+SDcDJPWaSJB1ixaJOchpwOfBBgKp6BXil31iSpIO6TH28EzgAfCHJw0luT3LK0pWSLCbZmWTngQMHph5Uko5XXYp6PXAx8Lmqugj4ObB56UpVtbWqFqpqYTAYTDmmJB2/uhT1fmB/Ve0Y3b6HYXFLkmZgxaKuqv8AfpzkvNFdVwI/6DWVJOk1Xb/1cRNw1+gbH08BH+ovkiTpUJ2KuqoeARb6jSJJGscjEyWpcRa1JDXOopakxlnUktQ4i1qSGmdRS1LjLGpJapxFLUmNs6glqXEWtSQ1zqKWpMZZ1JLUOItakhpnUUtS4yxqSWqcRS1JjbOoJalxnc7wkmQf8DLwS+DVqvJsL5I0I13PmQjwu1X1Ym9JJEljOfUhSY3rukVdwP1JCvibqtq6dIUki8AiwNzc3PQSSseA+c3bx96/b8umGSdZ2XJZl9PiGI41XbeoL6uqi4GrgT9OcvnSFapqa1UtVNXCYDCYakhJOp51Kuqqem705wvAvcAlfYaSJL1uxaJOckqSUw9eB34f2N13MEnSUJc56rcB9yY5uP6Xq+obvaaSJL1mxaKuqqeA35pBFknSGH49T5IaZ1FLUuMsaklqnEUtSY2zqCWpcRa1JDXOopakxlnUktQ4i1qSGmdRS1LjLGpJapxFLUmNs6glqXEWtSQ1zqKWpMZZ1JLUOItakhrXuaiTrEvycJL7+gwkSXqj1WxR3wzs7SuIJGm8TkWd5GxgE3B7v3EkSUt1OQs5wG3AJ4BTl1shySKwCDA3NzdxMEnTMb95+5GOoAmtuEWd5H3AC1W163DrVdXWqlqoqoXBYDC1gJJ0vOsy9XEZcG2SfcBXgCuS3NlrKknSa1Ys6qr6ZFWdXVXzwPXAP1XVjb0nkyQBfo9akprXdWciAFX1APBAL0kkSWO5RS1JjbOoJalxFrUkNc6ilqTGWdSS1DiLWpIaZ1FLUuMsaklqnEUtSY2zqCWpcRa1JDXOopakxlnUktQ4i1qSGmdRS1LjLGpJapxFLUmN63IW8hOTPJjk0SR7knxqFsEkSUNdTsX1v8AVVfWzJCcA303y9ar6Xs/ZJEl0KOqqKuBno5snjC7VZyhJ0us6ndw2yTpgF/BrwGeraseYdRaBRYC5ublpZlQj5jdvH3v/vi2bZpxERwM/L9PTaWdiVf2yqi4EzgYuSXLBmHW2VtVCVS0MBoMpx5Sk49eqvvVRVT8FHgCu6iOMJOnNunzrY5Bk4+j6ScB7gcd7ziVJGukyR30m8MXRPPVbgK9W1X39xpIkHdTlWx+PARfNIIskaQyPTJSkxlnUktQ4i1qSGmdRS1LjLGpJapxFLUmNs6glqXEWtSQ1zqKWpMZZ1JLUOItakhpnUUtS4yxqSWqcRS1JjbOoJalxFrUkNc6ilqTGdTln4jlJvp1kb5I9SW6eRTBJ0lCXcya+CvxZVT2U5FRgV5J/rKof9JxNkkSHLeqqer6qHhpdfxnYC5zVdzBJ0lCXLerXJJlneKLbHWOWLQKLAHNzc9PIpimZ37x9Vevv27KppySvWy7TLH720aLF901HRuediUneCnwNuKWqXlq6vKq2VtVCVS0MBoNpZpSk41qnok5yAsOSvquqtvUbSZJ0qC7f+gjweWBvVf1l/5EkSYfqskV9GfAB4Iokj4wu1/ScS5I0suLOxKr6LpAZZJEkjeGRiZLUOItakhpnUUtS4yxqSWqcRS1JjbOoJalxFrUkNc6ilqTGWdSS1DiLWpIaZ1FLUuMsaklqnEUtSY2zqCWpcRa1JDXOopakxlnUktS4LudMvCPJC0l2zyKQJOmNumxR/y1wVc85JEnLWLGoq+o7wE9mkEWSNMaKJ7ftKskisAgwNze35ueZ37x97P37tmxa83NOorU8s7DcmGfxPNP62dPSd55pPn9rr91yjse/U5Oa2s7EqtpaVQtVtTAYDKb1tJJ03PNbH5LUOItakhrX5et5dwP/ApyXZH+SD/cfS5J00Io7E6vqhlkEkSSN59SHJDXOopakxlnUktQ4i1qSGmdRS1LjLGpJapxFLUmNs6glqXEWtSQ1zqKWpMZZ1JLUOItakhpnUUtS4yxqSWqcRS1JjbOoJalxFrUkNa5TUSe5KskTSX6YZHPfoSRJr+tyzsR1wGeBq4HzgRuSnN93MEnSUJct6kuAH1bVU1X1CvAV4Lp+Y0mSDkpVHX6F5P3AVVX1kdHtDwDvqqqPLVlvEVgc3TwPeGKNmc4AXlzjY49WjvnYd7yNFxzzar2jqgbjFqx4FnIgY+57U7tX1VZg6yqDvfmHJTuramHS5zmaOOZj3/E2XnDM09Rl6mM/cM4ht88Gnpt2EEnSeF2K+l+BX09ybpINwPXAP/QbS5J00IpTH1X1apKPAd8E1gF3VNWeHjNNPH1yFHLMx77jbbzgmKdmxZ2JkqQjyyMTJalxFrUkNW5mRb3SYehJTk9yb5LHkjyY5IKuj23VWsec5Jwk306yN8meJDfPPv3aTPI+j5avS/Jwkvtml3oyE362Nya5J8njo/f70tmmX5sJx/zx0ed6d5K7k5w42/Srl+SOJC8k2b3M8iT569Hr8ViSiw9ZNnl/VVXvF4Y7IZ8E3glsAB4Fzl+yzqeBW0fXfwP4VtfHtniZcMxnAhePrp8K/NuxPuZDlv8p8GXgviM9nlmMGfgi8JHR9Q3AxiM9pj7HDJwFPA2cNLr9VeCDR3pMHcZ8OXAxsHuZ5dcAX2d43Mm7gR1dX6sul1ltUXc5DP184FsAVfU4MJ/kbR0f26I1j7mqnq+qh0b3vwzsZfgBb90k7zNJzgY2AbfPLvLE1jzmJKcxLIDPj5a9UlU/nVnytZvofWb4bbOTkqwHTuYoOC6jqr4D/OQwq1wHfKmGvgdsTHImU+qvWRX1WcCPD7m9nzcXz6PAHwIkuQR4B8ODa7o8tkWTjPk1SeaBi4AdfQWdoknHfBvwCeD/ek05XZOM+Z3AAeALo+me25Oc0n/kia15zFX1LPAZ4BngeeC/qur+3hP3b7nXZCr9Naui7nIY+hbg9CSPADcBDwOvdnxsiyYZ8/AJkrcCXwNuqaqXeso5TWsec5L3AS9U1a5+I07dJO/zeoa/Tn+uqi4Cfg4cDftgJnmfT2e4RXku8HbglCQ39ph1VpZ7TabSX13+r49pWPEw9FERfQiGE/MM57GeZvir0dF4CPskYybJCQxL+q6q2jaLwFMwyZivB65Ncg1wInBakjurqvW/xJN+tvdX1cHflu7h6CjqScb8B8DTVXVgtGwb8B7gzv5j92q512TDMvevzowm4tcDTzH8V/TghPpvLllnI7BhdP2PGM73dHpsi5cJxxzgS8BtR3ocsxrzknV+h6NnZ+JEYwb+GThvdP0vgE8f6TH1OWbgXcAehv9IheHO1JuO9Jg6jnue5XcmbuKNOxMf7PpadfrZMxzkNQy/vfAk8Oej+z4KfHR0/VLg34HHgW3A6Yd77NFwWeuYgd9m+OvRY8Ajo8s1R3o8fb/PhzzHUVPUk44ZuBDYOXqv/37c69HiZcIxf2p0/27g74BfOdLj6TDeuxnOqf+C4dbzh5eMNwxPsPIk8H1g4XCv1WovHkIuSY3zyERJapxFLUmNs6glqXEWtSQ1zqKWpMZZ1JLUOItakhr3/45AbrlVMi5OAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(neg, 50, range=(0.9,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2b7bc2a948c5289c5d753f7423e04c08b765fb863c039d52055e17d54349c5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
